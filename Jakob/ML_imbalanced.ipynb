{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bee60830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, auc, confusion_matrix, precision_score, pairwise\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5f131667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>melanoma</th>\n",
       "      <th>Norm_Compactness</th>\n",
       "      <th>Norm_Asymmetry</th>\n",
       "      <th>Norm_Average Color</th>\n",
       "      <th>Norm_Age</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434213</td>\n",
       "      <td>0.565848</td>\n",
       "      <td>0.512858</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079822</td>\n",
       "      <td>0.714482</td>\n",
       "      <td>0.513188</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.312995</td>\n",
       "      <td>0.818309</td>\n",
       "      <td>0.657999</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346936</td>\n",
       "      <td>0.747794</td>\n",
       "      <td>0.628721</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381283</td>\n",
       "      <td>0.671515</td>\n",
       "      <td>0.458960</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   melanoma  Norm_Compactness  Norm_Asymmetry  Norm_Average Color  Norm_Age  \\\n",
       "0       0.0          0.434213        0.565848            0.512858  0.647059   \n",
       "1       0.0          0.079822        0.714482            0.513188  0.352941   \n",
       "2       1.0          0.312995        0.818309            0.657999  0.705882   \n",
       "3       0.0          0.346936        0.747794            0.628721  0.352941   \n",
       "4       1.0          0.381283        0.671515            0.458960  0.941176   \n",
       "\n",
       "   Sex  \n",
       "0    1  \n",
       "1    1  \n",
       "2    1  \n",
       "3    0  \n",
       "4    0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the features normalised and dropping all the non relevant columns to have a clean start\n",
    "df = pd.read_csv(\"../data/processed/ISIC_2017_norm_features.csv\")\n",
    "df = df.drop([\"seborrheic_keratosis\", \"Perimeter\", \"Area\", \"image_id\", \"Red\", \"Green\", \"Blue\"], axis=1)\n",
    "\n",
    "\n",
    "df.head()\n",
    "#Note: for sex, 1 is female, 0 is male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fa7cf820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying the dataframe. it should be with .copy() but it works like this too\n",
    "df2 = df.copy()\n",
    "\n",
    "\n",
    "# Some noisy features\n",
    "noise = np.random.RandomState(42).uniform(0, 0.1, size=(df2.shape[0], 20))\n",
    "\n",
    "# Add the noisy data to the informative features\n",
    "# this is not something that makes sense to me. we add the noise to then ignore it in the next cell\n",
    "X = np.hstack((df2[['Norm_Compactness', 'Norm_Asymmetry', \"Norm_Average Color\"]], noise))\n",
    "y = df2['melanoma'].astype(\"int32\")\n",
    "\n",
    "\n",
    "# Split dataset to select feature and evaluate the classifier\n",
    "# the splitting is done by splitting the data into data to be used for training and validation (development of the model --> dev), and data to be used for testing. \n",
    "X_dev, _, y_dev, _ = train_test_split(\n",
    "        X, y, stratify=y)\n",
    "\n",
    "# the development data is split into training and validation.\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_dev, y_dev, stratify=y_dev)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#OverSampling to compensate for imbalanced dataset\n",
    "oversample = RandomOverSampler(sampling_strategy = 0.75)\n",
    "X_over, y_over = oversample.fit_resample(X,y)\n",
    "\n",
    "\n",
    "#Splitting oversampled data \n",
    "# Split dataset to select feature and evaluate the classifier\n",
    "# the splitting is done by splitting the data into data to be used for training and validation (development of the model --> dev), and data to be used for testing. \n",
    "X_dev, _, y_dev, _ = train_test_split(\n",
    "        X_over, y_over, stratify=y_over)\n",
    "\n",
    "# the development data is split into training and validation.\n",
    "X_train_over, X_val_over, y_train_over, y_val_over = train_test_split(\n",
    "        X_dev, y_dev, stratify=y_dev)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6f6f33b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8366597465817166 0.9096018735362996\n",
      "0.7378838857470112 0.7996487119437938\n",
      "0.7039587658386426 0.7967213114754099\n",
      "0.6674493521368745 0.7058548009367681\n",
      "0.6739494595175031 0.6891100702576113\n",
      "0.6532536330445987 0.6510538641686184\n",
      "0.6761257069224712 0.6984777517564402\n",
      "0.6428663469110173 0.6230679156908665\n",
      "0.6499248335600257 0.6298594847775175\n",
      "0.6406686233803421 0.6154566744730678\n",
      "0.6411768916887394 0.6485948477751757\n",
      "0.6450425943159854 0.6505854800936768\n",
      "0.6564750519006372 0.6688524590163935\n",
      "0.6423079676426373 0.6412177985948478\n",
      "0.6324575846517287 0.6413348946135831\n",
      "0.6324933781945739 0.6389929742388759\n",
      "0.6291860548357077 0.6725995316159251\n",
      "0.6292003722528456 0.6577283372365339\n",
      "0.6324504259431598 0.6441451990632319\n",
      "0.6319278402176248 0.6385245901639344\n",
      "0.636280335027561 0.6451990632318501\n",
      "0.6324790607774357 0.6297423887587822\n",
      "0.6286276755673276 0.6314988290398127\n",
      "0.6144605913093278 0.6297423887587822\n",
      "0.6160856181544849 0.6539812646370023\n",
      "0.6122843439043597 0.6505854800936768\n",
      "0.6046173670269883 0.6676814988290398\n",
      "0.5948099362874938 0.6577283372365339\n",
      "0.6035292433245042 0.6523419203747073\n",
      "0.6090056553797696 0.6544496487119438\n",
      "0.599699334240103 0.6451990632318501\n",
      "0.5899062209177465 0.6401639344262295\n",
      "0.5942515570191138 0.6447306791569085\n",
      "0.9096018735362996\n",
      "{1: 0.9096018735362996, 2: 0.888407494145199, 3: 0.8498829039812646, 4: 0.8133021077283372, 5: 0.7850117096018736, 6: 0.7654332552693208, 7: 0.7559016393442624, 8: 0.7361826697892272, 9: 0.7246135831381733, 10: 0.7200702576112412, 11: 0.7249180327868853, 12: 0.7259250585480094, 13: 0.7282201405152224, 14: 0.7259250585480094, 15: 0.726814988290398, 16: 0.728384074941452, 17: 0.7224824355971897, 18: 0.7123419203747073, 19: 0.7030444964871194, 20: 0.7025058548009367, 21: 0.6986182669789227, 22: 0.7034660421545668, 23: 0.7027868852459016, 24: 0.698056206088993, 25: 0.6985480093676815, 26: 0.7046370023419204, 27: 0.709344262295082, 28: 0.70672131147541, 29: 0.7054566744730679, 30: 0.7035128805620608, 31: 0.699695550351288, 32: 0.696112412177986, 33: 0.6951990632318501}\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier\n",
    "X_train_over = X_train_over[:,0:3] # Take only wanted features\n",
    "X_val = X_val[:, 0:3] # Take only wanted features\n",
    "X_val_over = X_val_over[:,0:3]\n",
    "roc_dict = {}\n",
    "knn_list = [None]\n",
    "\n",
    "neigh = int(math.sqrt(len(X_train)))\n",
    "neigh\n",
    "# the range is to the neigh, as some sources suggest to use the square root of the number of datapoints, and it does seem as a fair estimation to decrease error\n",
    "for i in range(1, neigh+1):\n",
    "    #train the model with different values of the neighbors\n",
    "    knn1 = KNeighborsClassifier(n_neighbors=i) \n",
    "    knn1trained = knn1.fit(X_train_over, y_train_over)\n",
    "    \n",
    "    #Select the same features as before\n",
    "    \n",
    "    y_val_knn1 = knn1trained.predict_proba(X_val)\n",
    "    print(roc_auc_score(y_val_over,knn1trained.predict(X_val_over)),roc_auc_score(y_val,knn1trained.predict(X_val)))\n",
    "    \n",
    "    #adding the roc_score value to the dictionary to assess which is the best\n",
    "    # can be calculated with another calculation, but it would be time consuming to do both to show they are identical\n",
    "    fpr, tpr, threshold = roc_curve(y_val, y_val_knn1[:,1])\n",
    "    roc_test = auc(fpr,tpr)\n",
    "    roc_dict[i] = roc_test\n",
    "    knn_list.append(knn1trained)\n",
    "\n",
    "\n",
    "# getting all the values with the highest accuracy score\n",
    "max_keys = [key for key, value in roc_dict.items() if value == max(roc_dict.values())]\n",
    "\n",
    "# we use the biggest of the neighbors values as the neighbor to use for the classification, as a lower value is not recomended \n",
    "print(roc_dict[max_keys[-1]])\n",
    "\n",
    "#best trained knn algorithm\n",
    "final_knn_trained = knn_list[max_keys[-1]]\n",
    "print(roc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ade6b7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA08ElEQVR4nO3dd5gUVdbA4d9xSJIVEEUEUbISRMCIohhAEbNiYvXTRURFZVEQdQ2Yc8KArIsRVjFhAszZVVYyTZI4AhJEBIbgzJzvj1vjNM1MT81MV1d3z3mfp5/p6q6uOl1ina57b50rqooxxhhTnF3CDsAYY0xqs0RhjDEmLksUxhhj4rJEYYwxJi5LFMYYY+KyRGGMMSYuSxTGpAkRuVNE1orIqiLe6y4i2WHEZTKfJQoTChFZIiJbRGSTiKwSkTEiUjNmncNF5FMR2SgiG0TkXRFpG7NObRF5VESWedta6C3XL2a/IiKDRGSWiGwWkWwReV1E2gX5fctLRPYB/gG0VdU9S/nZ7iKiIjIy5vWvReRi7/nF3jrXx6yTLSLdyxW8SXuWKEyYTlHVmkBH4CDgxoI3ROQwYDLwDtAIaAZMB74Rkf28daoAnwAHAD2B2sDhwDqgazH7fAy4BhgE7A60BN4GTi5t8CJSqbSfKYemwDpVXV3Gz28G+onIvnHW+Q0YKiK1y7gPk6EsUZjQqeoqYBIuYRS4H3hRVR9T1Y2q+puq3gx8D9zmrdMPaAKcrqpzVDVfVVer6ghV/SB2PyLSArgSOE9VP1XVbaqao6qvqOq93jqfi8hlUZ+5WES+jlpWEblSRBYAC0TkGRF5MGY/74jIYO95IxF5Q0TWiMhiERlU3HEQkToi8qK37lIRuVlEdhGR44CPgEbeVdOYko6pd9U0R0Qaey/9DowBbo3zsQjwHXBdSds3FYslChM672TWC1joLVfHXRm8XsTqrwHHe8+PAyaq6iafu+oBZKvqD+WLmNOAQ4C2wKvAuSIiACKyG3ACME5EdgHexV0J7e3t/1oRObGY7T4B1AH2A47GJcJLVPVj3PFZoao1VfXieMGJyC3AxcDRqhrdb3EXcKaItIrz8VuA60Rk93j7MBWLJQoTprdFZCOwHFhN4a/d3XH/NlcW8ZmVQEH/Q71i1ilOadcvzj3eFc4W4CtAgW7ee2cB36nqCqAL0EBV71DV7aq6CHgO6Bu7QRHJAs4FbvSuoJYADwEXlSIuEZGHgROBY1R1TfSb3pXbM8AdxW1AVafhmvyGlmK/JsNZojBhOk1VawHdgdYUJoD1QD6wVxGf2QtY6z1fV8w6xSnt+sVZXvBEXVXNccB53kvnA694z5vimot+L3gAw4GGRWyzPlAFWBr12lLclYhfdYH+uES2oZh17gNOFJEOcbbzT+AKESlVp7nJXJYoTOhU9Qtc+/mD3vJmXFv52UWsfg6uAxvgY9xJr4bPXX0CNBaRznHW2QxUj1ou6mQZW3J5LHCWiDTFNUm94b2+HFisqnWjHrVU9aQitrkW+BOXXAo0AX6JE2us9UBv4N8ickRRK6jqOuBRYERxG1HVucCbuKRmjCUKkzIeBY4XkY7e8jDgb16nbC0R2U1E7gQOA2731nkJdzJ+Q0Raex2/9URkuIjsdDJW1QXAU8BYb8hoFRGpJiJ9RWSYt9o04AwRqS4izYFLSwpcVacCa4DRwCRV/d176wfgDxEZKiK7ikiWiBwoIl2K2EYerv/lLu/7NgUGAy+XtP+Y7XwOXAC8JSKHFLPaw7g+oDZxNnU7cAnuKsVUcJYoTErw2tNfxHWmoqpf49raz8D1KyzFDaE90jvho6rbcB3ac3Gjgv7AnZzrA/8tZleDgCeBkbiRQD8Dp+M6nQEeAbYDvwIvUNiMVJKxXiyvRn2nPOAU3GiuxbirhtG4DuuiXI27olkEfO1t63mf+/+Lqn6EO8lPEJGDi3j/D9yosmI7rFV1MS4R+71aMxlMbOIiY4wx8dgVhTHGmLgCSxQi8ryIrBaRWcW8LyLyuFdyYYaIdAoqFmOMMWUX5BXFGFxZheL0Alp4j/7A0wHGYowxpowCSxSq+iWudkxxTsWVaFBV/R6oKyKJGONujDEmgZJZ1CzW3kTduARke6/tdOesiPTHXXVQo0aNg1u3bp2UAI0xJplUIS9v50durr/X8vJ23uaerGQvVjGV/LWq2qAscYWZKKSI14ocgqWqo4BRAJ07d9YpU6YEGZcxxpTJtm2wYQP8/nvhozTLm3xULatdG+rWhTp13N+Cx07LtZW6uwlNp0+gwdTJ7PbKyKVxNhtXmIkiG9gnarkxsCKkWIwxFZwq5OSU70S/dWv8feyyy84n9hYtfJ7467gkkZVVwhdZvx6GDIH99oObboLj+gB94JWRJXyweGEmignAVSIyDlf2YIOqJqJgmzGmAsrPh40by3eiz82Nv4/KlWG33XY8kTdp4v9EX7MmSFFtKYny1lswcCCsWQM335ywzQaWKERkLK7YW31xUzTeClQGUNVngA+Ak3ClpXNwd5IaYyqo3Fx30i7riX7DBndVEE/16jueuPfYA1q29H+ir1Yt4BN9Wf36K1x9Nbz+OnTsCO+/D50Sd8dBYIlCVc8r4X3FTSJjjMkA27aV/hd89HJp2ucLTtwFv+b9nugrV07oV04dy5e75HDXXXD99Qn/omE2PRljUkRB+3x5TvSlaZ8vOHEX/Jr3c6KvVctH+3xFsnQpvPsuXHUVdO4My5ZBvXqB7MoShTEZoKB9vjwn+pLa56tU2flEXppf9DVqpGizTbrJz4enn4ZhXsHjM8+EvfYKLEmAJQpjUkJB+3xZT/R+2udr1Njx5N2w4Y6/6Es62VerlvjvbUpp3jy47DL4+ms48UR49lmXJAJmicKYBChony/rid5P+3ydOjueuJs2hfbt/Z3oM7p9vqLIyYEjj3R31Y0ZA/36Je0SzRKFqfCi2+fLeqIvqX0+K2vnE3mrVv46YK19voKbP9/dbFG9Orz0khvVtGdyZ6m1RGHSXnT7fFlP9H7a53fbbedf9H5P9NY+b0pt61YYMQLuu89dQVx4IfSMV2c1OJYoTOii2+fLcqL/4w9/7fPRJ+6GDUv3i97a501SffMNXHqp65O45BI4+eRQw7FEYcotun2+LCf6zZtL3kd0W3vBr/kOHfyd6K193qSVESPg1lvdkLJJk+CEE8KOyBJFRRfbPl+WE/22bfH3UdA+H30ib9XK/01S1j5vKgRV1z7ZsaO7y/quu1zNjxRgiSLNxbbPl+VEX1Rp4mgF7fOxv+j9nuitfd6YOH77Da67Dpo3h1tugVNOcY8UYokiZLHt86U90Zemfb7gxF3QPl+a+jbGmACMHw9XXumSxS23hB1NsSxRlNPWreU70ZfUPi+yc32bgvZ5Pyf62rWtfd6YlLNypSu98eabcPDBMHmy+586RVmiKIXRo+G553Y80Zemfb7gseee/u+GrVXL1cgxxmSQFStcR/V998HgwVAptU/FqR1dihk50lXz7dbN/4m+enVrnzfGAEuWuCJ+V1/triKWL3edf2nAEoVP+fluSPOAAfDww2FHY4xJG3l57lfm8OGueeDss12zQpokCQBr1PBp6VLYsgXatAk7EmNM2ohE4Kij4JprXFPErFlJL7+RCHZF4VMk4v5aojDG+JKT45JEfj68+KIrwZGm7dCWKHyyRGGM8WXuXDf+vHp1eOUVN5qpYcOwoyoXa3ryKRKBBg0CnRvEGJPOtmyBoUPhgANcggBXfiPNkwTYFYVvkYhdTRhjivHll25CoQUL3N/evcOOKKHsisIHVUsUxphi3H47HH20K7Pw8cfuZqu6dcOOKqEsUfiwejWsX2+JwhgTpaB2TufOrlbTzJnQo0e4MQXEEoUP1pFtjPnL2rVw0UWuHDi4uSIeftgVVctQlih8sERhjEEVXnsN2raFceMqVG0d68z2IRJxZeEbNw47EmNMKFasgIED4Z13XFPTxx9D+/ZhR5U0FScllkMkAq1bp+29MsaY8lq1Cj79FB54AL77rkIlCbArCl8iETj22LCjMMYk1aJFMGECXHstdOoEy5Zl3Ggmv+yKogR//AG//GL9E8ZUGHl58MgjcOCBbu7qVavc6xU0SYAlihLNnev+WqIwpgKYPRuOOMLNEXHssW45DYv4JZo1PZXARjwZU0Hk5Lgb50Tg1Vehb1/rmPRYoihBJOKmEt1//7AjMcYEYs4c90uwenU37LVDB1fYzfzFmp5KEIlAixYpP1OhMaa0cnLg+uuhXTt4+WX32nHHWZIogp3+ShCJVLiRcMZkvs8/h7//HRYuhMsvhz59wo4opdkVRRzbtsHPP1v/hDEZ5dZb4Zhj3J3Wn34KzzzjJro3xbJEEceCBW5yKksUxmSAgiJ+XbvCP/4BM2a4hGFKFGiiEJGeIjJPRBaKyLAi3q8jIu+KyHQRmS0ilwQZT2nZiCdjMsCaNXD++XDHHW755JPhwQdd57XxJbBEISJZwEigF9AWOE9E2sasdiUwR1U7AN2Bh0SkSlAxlVYk4kbHtWoVdiTGmFJTdcNc27SB8eOhSsqcWtJOkFcUXYGFqrpIVbcD44BTY9ZRoJaICFAT+A3IDTCmUolEoGlT++FhTNrJznYd1BdcAM2bw9SpcOONYUeVtoJMFHsDy6OWs73Xoj0JtAFWADOBa1Q1P3ZDItJfRKaIyJQ1a9YEFe9ObFY7Y9LUmjVuetKHH4ZvvnHzWJsyCzJRFHVLo8YsnwhMAxoBHYEnRaT2Th9SHaWqnVW1c4MkjXHOy4N58yxRGJM2Fi50NZoADjoIli93M89lZYUbVwYIMlFkA/tELTfGXTlEuwR4U52FwGKgdYAx+bZ0KWzdaonCmJSXm+s6p9u1c/NX//qre732Tr85TRkFmSh+BFqISDOvg7ovMCFmnWVADwARaQi0AhYFGJNvNuLJmDQwcyYcfri7w/qEE1wRv4YNw44q4wR2Z7aq5orIVcAkIAt4XlVni8gA7/1ngBHAGBGZiWuqGqqqa4OKqTQsURiT4nJy3H0Qu+ziajSdc44V8QtIoCU8VPUD4IOY156Jer4COCHIGMoqEoE99oDddw87EmPMDmbNcp3T1avDf/7jivjVrx92VBnN7swuho14MibFbN7s5olo376wiF+PHpYkksASRRFULVEYk1I++cR1Vj/yCFxxBZwae0uWCZIliiL8+iv8/rslCmNSwi23uPLflSrBF1/AyJE2oinJLFEUwTqyjUkB+d69t4cfDjfcANOnw1FHhRtTBWWJogiWKIwJ0erVbhrS2293y716wX33wa67hhtXBWaJogiRCNSqBXvHFhwxxgRH1XVSt2kDb71lRdZSiCWKIkQi0Lq1Dck2JmmWL4feveGii1y55qlTYejQsKMyHksURbART8Yk2bp1rnjfY4/BV19B29gZCUyYbM7sGBs2wIoVliiMCdz8+TBhAgwZAh07uquKWrXCjsoUwa4oYsyd6/5aojAmILm5rnO6fXu4667CIn6WJFKWJYoYNuLJmABNnw6HHALDhsFJJ8GcOVbELw1Y01OMSMTNmLjffmFHYkyGyclxJTcqVXJTk555ZtgRGZ8sUcSIRKBFC/dv2RiTADNmuPIb1avD66+7In5WbTOtWNNTDBvxZEyCbNoE11zjOqpfesm9dswxliTSkCWKKFu3wqJFliiMKbePPnJXEY8/DldeCaefHnZEphwsUURZsMCVl7FEYUw53HSTm22ualV3T8QTT9iIpjTnO1GISI0gA0kFNuLJmHIoKOJ35JFw440wbZp7btJeiYlCRA4XkTlAxFvuICJPBR5ZCCIRV7ajVauwIzEmjaxaBWedBbfd5pZ79YK774Zq1UINyySOnyuKR4ATgXUAqjodyMhav5EI7LuvFak0xhdVGDPGldt47z2bIyKD+RoEqqrLZccKeXnBhBMuG/FkjE9Ll0L//jB5smteGj3aLsUzmJ8riuUicjigIlJFRIbgNUNlkrw8mDfPEoUxvvz+O/z4Izz5pJt1zpJERvNzRTEAeAzYG8gGJgMDgwwqDEuWwLZtliiMKda8ea6I3/XXu5vmli2DmjXDjsokgZ8rilaqeoGqNlTVPVT1QiDjTqc24smYYvz5J9xzj0sO997rZqADSxIViJ9E8YTP19KaJQpjijB1qiviN3w4nHKKK+K3xx5hR2WSrNimJxE5DDgcaCAig6Peqg1kBR1YskUirojlbruFHYkxKSInB44/HipXhjfegDPOCDsiE5J4fRRVgJreOtG3Vf4BnBVkUGGwEU/GeKZOdfWZqld3VV47dLBfUBVcsYlCVb8AvhCRMaq6NIkxJZ2qSxTnnx92JMaEaONGd0f1yJHwwgvQrx907x52VCYF+Bn1lCMiDwAHAH/daqmqxwYWVZKtWuWmQLUrClNhTZwIl1/upiO95hprZjI78NOZ/QowF2gG3A4sAX4MMKaks45sU6HdeKMru1GjBnzzDTz6qI1oMjvwc0VRT1X/JSLXRDVHfRF0YMlkicJUSHl5kJXlmpcqVYKbb3YVX42J4SdR/On9XSkiJwMrgMbBhZR8kYirgtyoUdiRGJMEK1e6OSIOOABGjIATT3QPY4rhp+npThGpA/wDGAKMBq4NMqhkKxjxtGM5K2MyjCr8+9+uiN+HH9pIJuNbiVcUqvqe93QDcAyAiBwRZFDJFom4eVaMyVhLlsDf/w4ffwzdurkifi1bhh2VSRPxbrjLAs7B1XiaqKqzRKQ3MBzYFTgoOSEGa8MGdyVu/RMmo23YAD/9BE895UY37WKTWxr/4v1r+RdwGVAPeFxE/g08CNyvqr6ShIj0FJF5IrJQRIYVs053EZkmIrPD6CS3jmyTsebMcbWZoLCI3xVXWJIwpRav6akz0F5V80WkGrAWaK6qq/xs2LsiGQkcj6s6+6OITFDVOVHr1AWeAnqq6jIRSXoRGUsUJuNs3w733+86qmvVgv/7P1efqUbGz2ZsAhLvp8V2Vc0HUNWtwHy/ScLTFVioqotUdTswDjg1Zp3zgTdVdZm3n9Wl2H5CRCJQpQo0a5bsPRsTgClToEsXuOUWd9OcFfEzCRDviqK1iMzwnguwv7csgKpq+xK2vTewPGo5GzgkZp2WQGUR+RxXT+oxVX0xdkMi0h/oD9CkSZMSdls6kYjr06vka64/Y1LY5s1umGu1avDOO9CnT9gRmQwR7/RY3saYogabahH7Pxjogesg/05EvlfV+Tt8SHUUMAqgc+fOsdsol0gEOnVK5BaNSbKffnJF/GrUgLfegvbtoW7dsKMyGaTYpidVXRrv4WPb2cA+UcuNcTfrxa4zUVU3q+pa4EugQ2m/RFlt3QqLF1v/hElTf/wBAwfCwQfDyy+71446ypKESbgghz/8CLQQkWYiUgXoC0yIWecdoJuIVBKR6rimqaTNxz1/PuTnW6IwaeiDD9yd1c8+C4MHw5lnhh2RyWCBtcyraq6IXAVMwk109LyqzhaRAd77z6hqREQmAjOAfGC0qs4KKqZYNuLJpKWhQ92oprZt3XwRh8R2/RmTWL4ShYjsCjRR1Xml2biqfgB8EPPaMzHLDwAPlGa7iRKJuLIddoOqSXmq7vI3Kwt69HAd1sOHWxE/kxQlNj2JyCnANGCit9xRRGKbkNJSJOKGxe66a9iRGBPHL7/AaafBrbe65RNOgNtvtyRhksZPH8VtuHsifgdQ1WnAvkEFlEw2/alJaarw3HOuiWnyZKhfP+yITAXlJ1HkquqGwCNJsrw815lticKkpMWLXRNT//5u/PbMmXDttWFHZSooP30Us0TkfCBLRFoAg4Bvgw0reIsXw7ZtlihMitq0CWbMcKOaLrvM6jOZUPn513c1br7sbcCruHLj1wYYU1LYiCeTcmbNgrvvds/btXNF/Pr3tyRhQufnX2ArVb1JVbt4j5u92k9pzRKFSRnbt7vO6U6d4JFHYLVX8qx69XDjMsbjJ1E8LCJzRWSEiBwQeERJEonAnnvaTawmZD/+6O6svu02OPtsK+JnUpKfGe6OEZE9cZMYjRKR2sB/VPXOwKMLkI14MqHbvBl69nTjsydMgFNOCTsiY4rkq/FTVVep6uPAANw9Ff8MMqigqVqiMCGaMsXdPFejhqvyOnu2JQmT0vzccNdGRG4TkVnAk7gRT40DjyxAK1e6emqWKExSbdjgpiHt0qWwiN+RR0KdOuHGZUwJ/AyP/TcwFjhBVWOrv6Yl68g2SffuuzBgAKxaBUOGwFlnhR2RMb756aM4NBmBJJMlCpNU118PDz7ohry+/ba7ojAmjRSbKETkNVU9R0RmsuOEQ35nuEtZkQjUrg177RV2JCZjqbrb/ytVcrWZatd2VV+rVAk7MmNKLd4VxTXe397JCCSZCjqypag5+Iwpr+xsuOIKN9PcXXfB8ce7hzFpKt4Mdyu9pwOLmN1uYHLCC4aNeDKByM93JTfatoVPP3U36hiTAfwMjy3qp1CvRAeSLL//7voTLVGYhFq0CI491nVYd+3qivhdfXXYURmTEPH6KK7AXTnsJyIzot6qBXwTdGBBsY5sE4jNm91d1aNHw//9n7VrmowSr4/iVeBD4B5gWNTrG1X1t0CjCpAlCpMwM2e6G+ZuvtmNaFq61GbBMhkpXtOTquoS4EpgY9QDEdk9+NCCEYm4icGaNQs7EpO2tm2Df/7TFfF7/PHCIn6WJEyGKumKojfwP9zw2OhraQX2CzCuwEQibo7srKywIzFp6fvv4dJLXTPTRRe5aq/16oUdlTGBKjZRqGpv729G/faORKBz57CjMGlp82Y4+WRXo+mDD6BX2o7pMKZU/NR6OkJEanjPLxSRh0WkSfChJd6WLW5mO+ufMKXy3/8WFvF7911XxM+ShKlA/AyPfRrIEZEOwA3AUuClQKMKyPz57oZZSxTGl99/d9OQHnpoYRG/ww+HWrVCDcuYZPOTKHJVVYFTgcdU9THcENm0YyOejG9vv+1unBszxpXeOPvssCMyJjR+qsduFJEbgYuAbiKSBVQONqxgRCJu+uGWLcOOxKS0wYNdJ3WHDq6p6eCDw47ImFD5SRTnAucD/6eqq7z+iQeCDSsYkYgbFlutWtiRmJQTXcTvpJPcSKYbboDKafmbyJiEKrHpSVVXAa8AdUSkN7BVVV8MPLIAWI0nU6Rly9xopltvdcvHHQc33WRJwhiPn1FP5wA/AGfj5s3+r4ik3awrubmuM9sShflLfj489RQccAB88QU0ahR2RMakJD9NTzcBXVR1NYCINAA+BsYHGViiLV4M27dbojCehQtdTaavvnIlwEeNgn33DTsqY1KSn0SxS0GS8KzD32iplGIjnswOtm51l5j//jf87W9WxM+YOPwkiokiMgk3bza4zu0PggspGJYoDNOmuSJ+t94KBx4IS5bYyAZjfPDTmX098CzQHugAjFLVoUEHlmiRiJv6tE6dsCMxSbd1q+uc7twZnn66sIifJQljfIk3H0UL4EFgf2AmMERVf0lWYIlmI54qqG+/dUX85s51TUwPPwy7p23xY2NCEe+K4nngPeBMXAXZJ5ISUQBULVFUSJs3wymnQE4OTJzo7rK2JGFMqcXro6ilqs95z+eJyE/JCCgIK1bAxo2WKCqM776DQw5xRfzee8/1R1h9JmPKLN4VRTUROUhEOolIJ2DXmOUSiUhPEZknIgtFZFic9bqISF5Q92dYR3YFsX69G/J6+OHwkle38rDDLEkYU07xrihWAg9HLa+KWlbg2Hgb9mpCjQSOB7KBH0VkgqrOKWK9+4BJpQvdP0sUFcCbb8KVV8KaNXDjjXDuuWFHZEzGiDdx0THl3HZXYKGqLgIQkXG4CrRzYta7GngD6FLO/RUrEnGjnfbcM6g9mFBddx08+ih07OgmFDrooLAjMiaj+LmPoqz2BpZHLWcDh0SvICJ7A6fjrk6KTRQi0h/oD9CkSennTCroyLZ7qjJIdBG/3r1hjz1gyBCrz2RMAIK8w7qo07LGLD8KDFXVvHgbUtVRqtpZVTs3aNCg1IHYiKcMs2QJ9OwJt9zilnv0cM1NliSMCUSQiSIb2CdquTGwImadzsA4EVkCnAU8JSKnJTKI9evh118tUWSE/Hx44gk3iunbb6Fp07AjMqZCKLHpSUQEuADYT1Xv8Oaj2FNVfyjhoz8CLUSkGfAL0Bc3r8VfVLVZ1H7GAO+p6tul+gYlsI7sDLFgAVxyCXzzjbuaeOYZSxTGJImfK4qngMOA87zljbjRTHGpai5wFW40UwR4TVVni8gAERlQxnhLzRJFhti+HX7+GV580XVYW5IwJmn8dGYfoqqdRGQqgKquF5Eqfjauqh8QU0BQVZ8pZt2L/WyztCIRqFrVKkinpalTXRG/225zc0YsWeL+YxpjksrPFcWf3r0OCn/NR5EfaFQJFIlAq1aQlRV2JMa3rVtd53SXLvDss+7eCLAkYUxI/CSKx4G3gD1E5C7ga+DuQKNKIBvxlGa+/ho6dIB774V+/WDOHCjDSDdjTOKU2PSkqq+IyP+AHrghr6epaiTwyBJgyxbXWvG3v4UdifFl0yY49VSoXRsmT3YzzxljQudn1FMTIAd4N/o1VV0WZGCJMG+euy/LrihS3Ndfu/pMNWvC+++74a81a4YdlTHG46fp6X1cufH3gU+ARcCHQQaVKDbiKcWtW+eal7p1Kyzid+ihliSMSTF+mp7aRS97lWMvDyyiBIpEYJddoGXLsCMxO1CF8ePhqqvgt9/cHdZ9+4YdlTGmGKWu9aSqP4lIYAX8EikSgf32s8EyKee66+Cxx+Dgg11fRIcOYUdkjInDTx/F4KjFXYBOwJrAIkogG/GUQlQhN9fVY+rTBxo1gsGDXVE/Y0xK89NHUSvqURXXV3FqkEElQm4uzJ9viSIlLF4MJ5xQWMTv2GPhhhssSRiTJuL+n+rdaFdTVa9PUjwJs2gR/PmnJYpQ5eXBk0/C8OHujsezzw47ImNMGRSbKESkkqrm+p32NNXYiKeQzZ8PF1/s5q/u1cvdYb3PPiV+zBiTeuJdUfyA64+YJiITgNeBzQVvquqbAcdWLnPnur+tW4cbR4WVmwtLl8LLL8P559usUcakMT+NxLsD63Cz0Cnu7mwFUjpRRCKuv7ROnbAjqUCmTHFF/EaMgLZtXfufDTkzJu3FSxR7eCOeZlGYIArEzlSXcmzEUxJt2QK33goPPeQmJh80yNVnsiRhTEaIN+opC6jpPWpFPS94pCxVSxRJ88UX0L49PPAAXHopzJ5tRfyMyTDxrihWquodSYskgVasgI0bLVEEbtMmOOMMqFsXPvnEDXs1xmSceIkibXsfbcRTwL76Co44wtVk+vBDN6lQjRphR2WMCUi8pqceSYsiwSxRBGTtWrjwQjjqqMIifl27WpIwJsMVe0Whqr8lM5BEikRca0jDhmFHkiFU4bXX4OqrYf1613FtRfyMqTAysoZCQUe2Dd1PkGuugSeecFOTfvIJtGtX8meMMRkjYxPFySeHHUWaU3U1UKpUgdNPh6ZN4dprbfJxYyogP0UB08r69fDrr9Y/US4//ww9esDNN7vlY46Bf/zDkoQxFVTGJQrryC6HvDx4+GHXtPS//0GrVmFHZIxJARnX9GSJoozmzoW//Q1++AFOOQWefhr23jvsqIwxKSAjE0W1aq5J3ZRCfr67U3HsWDj3XBsJYIz5S0YmilatrDndlx9+cEX87rrLFfH7+WfXeW2MMVEyso/Cmp1KkJMDQ4bAYYfBCy/AGm9mW0sSxpgiZFSi2LIFliyxRBHXZ5+5zuqHHoK//92K+BljSpRRTU/z5rnh/5YoirFpk5uOtG5dlzC6dw87ImNMGsioKwob8VSMzz93ndUFRfxmzLAkYYzxLeMSxS67QIsWYUeSItasgfPOczfMvfyye61LF6hePdy4jDFpJaOaniIR2H9/m1gNVTfMddAgNzHHiBFWxM8YU2YZlyis2QlX5XXkSDj0UPjXv9zQV2OMKaOMSRS5uTB/PvTuHXYkIcnPdwehShU46yxo3twlDLuhxBhTToH2UYhITxGZJyILRWRYEe9fICIzvMe3ItKhrPtatMgVO62QVxQLFrhpSG+6yS13726VXo0xCRNYohCRLGAk0AtoC5wnIrFtIIuBo1W1PTACGFXW/VXIEU+5ufDgg9C+PUybVsG+vDEmWYJseuoKLFTVRQAiMg44FZhTsIKqfhu1/vdA47LurCBRtG5d1i2kmUgE+vWDKVPg1FPhqaegUaOwozLGZKAgm572BpZHLWd7rxXnUuDDot4Qkf4iMkVEpqwpKDcRIxJxxU5r1y5ruGno11/hP/+Bt96yJGGMCUyQiaKo8qNa5Ioix+ASxdCi3lfVUaraWVU7Nyim3ESFGPH0/fdw443ueZs2rojfOedYpVdjTKCCTBTZwD5Ry42BFbEriUh7YDRwqqquK8uOVN10ChmbKDZvhuuug8MPh1deKSziV7lyuHEZYyqEIBPFj0ALEWkmIlWAvsCE6BVEpAnwJnCRqs4v645++cXdV5aRieLjj+HAA+HRR2HgQCviZ4xJusA6s1U1V0SuAiYBWcDzqjpbRAZ47z8D/BOoBzwlrvkkV1U7l3ZfGTviadMmd0f17rvDl19Ct25hR2SMqYACveFOVT8APoh57Zmo55cBl5V3PxmXKD79FI4+2hXxmzTJ3Vm9665hR2WMqaAyoihgJAK77QZ77BF2JOX066+uc7pHj8IifgcfbEnCGBOqjEkUbdqk8eAfVXjpJXflUDA16fnnhx2VMcYAGZYo0taVV7qb51q1cndYDx9uI5qMMSkj7YsC/vYbrF6dhokiP98Vp6paFc49132BgQOtPpMxJuWk/RVFWnZkz5vnOqsLivgdfbRVejXGpCxLFMn0559w773QoQPMmgXt2oUdkTHGlCjtm54iETcoqGnTsCMpwezZcNFFMHUqnHGGm1hozz3DjsoYY0qUEYmiVSs3V3ZKy8pyHSrjx8OZZ4YdjTHG+Jbqp9cSpfSIp2+/haFencPWrWHhQksSxpi0k9aJIicHli5NwUSxaRMMGgRHHunKgK9d616vlPYXcMaYCiitE8W8ee5etZRKFJMnuyJ+Tz4JV13lOq3r1w87KmOMKbO0/ombciOeNm2CCy6AevXgq6/giCPCjsgYY8otra8oIhHXR9yiRciBfPQR5OW5In6TJ7u7qy1JGGMyRNoniv33hypVQgpg5UrXOX3CCW5CIYCDDoJq1UIKyBhjEi/tE0UozU6qMGaMK+L3/vvuJjor4meMyVBp20eRmwsLFkCfPiHs/Ior4Nln3aim0aPdjRzGmJ38+eefZGdns3Xr1rBDqTCqVatG48aNqZzAwqJpmyh+/tlVxEjaFUV0Eb/zz4f27WHAgDS408+Y8GRnZ1OrVi323XdfJG3nAUgfqsq6devIzs6mWbNmCdtu2p7lkjriKRJx05AOH+6WjzrKVXq1JGFMXFu3bqVevXqWJJJERKhXr17Cr+DS9kxXkChatw5wJ3/+CXffDR07wty5rqPaGFMqliSSK4jjnbZNT5EING4MtWoFtIPZs+HCC91Q17PPhieegIYNA9qZMcakrrS+ogi02alSJdiwAd58E157zZKEMWnsrbfeQkSYO3fuX699/vnn9O7de4f1Lr74YsaPHw+4jvhhw4bRokULDjzwQLp27cqHH35Y7ljuuecemjdvTqtWrZg0aVKR60yfPp3DDjuMdu3accopp/DHH38AsG7dOo455hhq1qzJVVddVe5Y/ErLRKHqWoISnii++gqGDHHPW7WC+fPh9NMTvBNjTLKNHTuWI488knHjxvn+zC233MLKlSuZNWsWs2bN4t1332Xjxo3limPOnDmMGzeO2bNnM3HiRAYOHEheXt5O61122WXce++9zJw5k9NPP50HHngAcCOaRowYwYMPPliuOEorLZuesrNdtYyEJYqNG2HYMHjqKWjWzD2vX9+K+BmTQNde61pyE6ljR3j00fjrbNq0iW+++YbPPvuMPn36cNttt5W43ZycHJ577jkWL15M1apVAWjYsCHnnHNOueJ955136Nu3L1WrVqVZs2Y0b96cH374gcMOO2yH9ebNm8dRRx0FwPHHH8+JJ57IiBEjqFGjBkceeSQLFy4sVxyllZZXFAkd8fThh3DAAfD00+5f8syZVsTPmAzy9ttv07NnT1q2bMnuu+/OTz/9VOJnFi5cSJMmTahdu3aJ61533XV07Nhxp8e9996707q//PIL++yzz1/LjRs35pdfftlpvQMPPJAJEyYA8Prrr7N8+fIS4whSWv5kTlii2LgR+vWDPfZwc0ccemi5YzPGFK2kX/5BGTt2LNdeey0Affv2ZezYsXTq1KnY0UGlHTX0yCOP+F5XVX3t7/nnn2fQoEHccccd9OnThyqh1Sly0jZR7L47NGhQhg+rwqRJcPzxbsjUxx+7Mbbe5aUxJnOsW7eOTz/9lFmzZiEi5OXlISLcf//91KtXj/Xr1++w/m+//Ub9+vVp3rw5y5YtY+PGjdQqYWjlddddx2effbbT63379mXYsGE7vNa4ceMdrg6ys7Np1KjRTp9t3bo1kydPBmD+/Pm8//77vr9zENK26alNGyj1cOGVK9181b16FRbx69DBkoQxGWr8+PH069ePpUuXsmTJEpYvX06zZs34+uuvadGiBStWrCDiNVEsXbqU6dOn07FjR6pXr86ll17KoEGD2L59OwArV67k5Zdf3mkfjzzyCNOmTdvpEZskAPr06cO4cePYtm0bixcvZsGCBXTt2nWn9VavXg1Afn4+d955JwMGDEjkYSm1tE4UvqnC88+7D02cCPffb0X8jKkAxo4dy+kxIxfPPPNMXn31VapWrcrLL7/MJZdcQseOHTnrrLMYPXo0derUAeDOO++kQYMGtG3blgMPPJDTTjuNBmVqxih0wAEHcM4559C2bVt69uzJyJEjycrKAtxIpylTpvwVd8uWLWndujWNGjXikksu+Wsb++67L4MHD2bMmDE0btyYOXPmlCsmP6SoNrNU1rFjZ50+fQoPPQSDB/v80OWXw6hRrvTG6NEpMIGFMRVDJBKhTcrMLFZxFHXcReR/qtq5LNtLuz6KghImJf7by8tzJTiqVXN3WB90EPTvb/WZjDGmlNLurOkrUcye7WaYKyji162bVXo1xpgySrsz55YtUL06NGlSxJvbt8OIEe7qYeFC6NIl6fEZY3aUbs3b6S6I452WTU+tWhVxcTBzJlxwgfvbty88/ngZx88aYxKlWrVqrFu3zkqNJ0nBfBTVEjwdc1omiiKbnapUgZwceOedkKa9M8bEaty4MdnZ2axZsybsUCqMghnuEintEsX27VGJ4osvYMIEeOghd5kxbx54Q82MMeGrXLlyQmdaM+EItI9CRHqKyDwRWSgiO919Is7j3vszRKSTn+22a/qHm7e6e3d4+21Yu9a9YUnCGGMSLrBEISJZwEigF9AWOE9E2sas1gto4T36A0+XtN3abOCkGw5w90UMHmxF/IwxJmBBNj11BRaq6iIAERkHnApE30Z4KvCium7670Wkrojspaori9toM5aQtXsreHs8HHJIgOEbY4yBYBPF3kB0bdxsIPbMXtQ6ewM7JAoR6Y+74gDYljVn9iyr9ApAfWBt2EGkCDsWhexYFLJjUahVWT8YZKIoaixc7ABfP+ugqqOAUQAiMqWst6FnGjsWhexYFLJjUciORSERmVLWzwbZmZ0N7BO13BhYUYZ1jDHGhCjIRPEj0EJEmolIFaAvMCFmnQlAP2/006HAhnj9E8YYY5IvsKYnVc0VkauASUAW8LyqzhaRAd77zwAfACcBC4Ec4JLithdlVEAhpyM7FoXsWBSyY1HIjkWhMh+LtCszbowxJrnSriigMcaY5LJEYYwxJq6UTRRBlf9IRz6OxQXeMZghIt+KSIcw4kyGko5F1HpdRCRPRM5KZnzJ5OdYiEh3EZkmIrNF5Itkx5gsPv4fqSMi74rIdO9Y+OkPTTsi8ryIrBaRWcW8X7bzpqqm3APX+f0zsB9QBZgOtI1Z5yTgQ9y9GIcC/w077hCPxeHAbt7zXhX5WESt9ylusMRZYccd4r+LurhKCE285T3CjjvEYzEcuM973gD4DagSduwBHIujgE7ArGLeL9N5M1WvKP4q/6Gq24GC8h/R/ir/oarfA3VFZK9kB5oEJR4LVf1WVdd7i9/j7kfJRH7+XQBcDbwBrE5mcEnm51icD7ypqssAVDVTj4efY6FALXGTYtTEJYrc5IYZPFX9EvfdilOm82aqJoriSnuUdp1MUNrveSnuF0MmKvFYiMjewOnAM0mMKwx+/l20BHYTkc9F5H8i0i9p0SWXn2PxJNAGd0PvTOAaVc1PTngppUznzVSdjyJh5T8ygO/vKSLH4BLFkYFGFB4/x+JRYKiq5mX4jGp+jkUl4GCgB7Ar8J2IfK+q84MOLsn8HIsTgWnAscD+wEci8pWq/hFwbKmmTOfNVE0UVv6jkK/vKSLtgdFAL1Vdl6TYks3PsegMjPOSRH3gJBHJVdW3kxJh8vj9f2Stqm4GNovIl0AHINMShZ9jcQlwr7qG+oUishhoDfyQnBBTRpnOm6na9GTlPwqVeCxEpAnwJnBRBv5ajFbisVDVZqq6r6ruC4wHBmZgkgB//4+8A3QTkUoiUh1XvTmS5DiTwc+xWIa7skJEGuIqqS5KapSpoUznzZS8otDgyn+kHZ/H4p9APeAp75d0rmZgxUyfx6JC8HMsVDUiIhOBGUA+MFpVixw2mc58/rsYAYwRkZm45pehqppx5cdFZCzQHagvItnArUBlKN9500p4GGOMiStVm56MMcakCEsUxhhj4rJEYYwxJi5LFMYYY+KyRGGMMSYuSxQmJXmVX6dFPfaNs+6mBOxvjIgs9vb1k4gcVoZtjBaRtt7z4THvfVveGL3tFByXWV411LolrN9RRE5KxL5NxWXDY01KEpFNqloz0evG2cYY4D1VHS8iJwAPqmr7cmyv3DGVtF0ReQGYr6p3xVn/YqCzql6V6FhMxWFXFCYtiEhNEfnE+7U/U0R2qhorInuJyJdRv7i7ea+fICLfeZ99XURKOoF/CTT3PjvY29YsEbnWe62GiLzvzW0wS0TO9V7/XEQ6i8i9wK5eHK94723y/v4n+he+dyVzpohkicgDIvKjuHkCLvdxWL7DK+gmIl3FzUUy1fvbyrtL+Q7gXC+Wc73Yn/f2M7Wo42jMTsKun24PexT1APJwRdymAW/hqgjU9t6rj7uztOCKeJP39x/ATd7zLKCWt+6XQA3v9aHAP4vY3xi8uSuAs4H/4grqzQRq4EpTzwYOAs4Enov6bB3v7+e4X+9/xRS1TkGMpwMveM+r4Cp57gr0B272Xq8KTAGaFRHnpqjv9zrQ01uuDVTynh8HvOE9vxh4MurzdwMXes/r4uo+1Qj7v7c9UvuRkiU8jAG2qGrHggURqQzcLSJH4cpR7A00BFZFfeZH4Hlv3bdVdZqIHA20Bb7xyptUwf0SL8oDInIzsAZXhbcH8Ja6onqIyJtAN2Ai8KCI3IdrrvqqFN/rQ+BxEakK9AS+VNUtXnNXeymcka8O0AJYHPP5XUVkGrAv8D/go6j1XxCRFrhqoJWL2f8JQB8RGeItVwOakJk1oEyCWKIw6eIC3MxkB6vqnyKyBHeS+4uqfuklkpOBl0TkAWA98JGqnudjH9er6viCBRE5rqiVVHW+iByMq5lzj4hMVtU7/HwJVd0qIp/jyl6fC4wt2B1wtapOKmETW1S1o4jUAd4DrgQex9Uy+kxVT/c6/j8v5vMCnKmq8/zEawxYH4VJH3WA1V6SOAZoGruCiDT11nkO+BduSsjvgSNEpKDPobqItPS5zy+B07zP1MA1G30lIo2AHFV9GXjQ20+sP70rm6KMwxVj64YrZIf394qCz4hIS2+fRVLVDcAgYIj3mTrAL97bF0etuhHXBFdgEnC1eJdXInJQcfswpoAlCpMuXgE6i8gU3NXF3CLW6Q5ME5GpuH6Ex1R1De7EOVZEZuASR2s/O1TVn3B9Fz/g+ixGq+pUoB3wg9cEdBNwZxEfHwXMKOjMjjEZN7fxx+qm7gQ3l8gc4CcRmQU8SwlX/F4s03Flte/HXd18g+u/KPAZ0LagMxt35VHZi22Wt2xMXDY81hhjTFx2RWGMMSYuSxTGGGPiskRhjDEmLksUxhhj4rJEYYwxJi5LFMYYY+KyRGGMMSau/wcO0Yv6cS+7TgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_scores = final_knn_trained.predict_proba(X_val)\n",
    "fpr, tpr, threshold = roc_curve(y_val, y_scores[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN')\n",
    "plt.show()\n",
    "print(y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a8b43bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276 29 6 64\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = (confusion_matrix(y_val,final_knn_trained.predict(X_val))).ravel()\n",
    "print(tn,fp,fn,tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "031a7169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 1,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_knn_trained.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "58afb258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-141-aba9a2797253>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-141-aba9a2797253>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    X_val = X_val[:, 0:2]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier\n",
    "X_train_over = X_train_over[:,0:2] # Take only wanted features\n",
    "roc_dict = {}\n",
    "\n",
    "\n",
    "# the range is to the neigh, as some sources suggest to use the square root of the number of datapoints, and it does seem as a fair estimation to decrease error\n",
    "\n",
    "\n",
    "gnb = GaussianNB() \n",
    "gnb = gnb.fit(X_train_over, y_train_over)\n",
    "    \n",
    "#Select the same features as before\n",
    "X_val = X_val[:, 0:2]\n",
    "y_val_gnb = gnb.predict_proba(X_val)\n",
    "print(roc_auc_score(y_val,gnb.predict(X_val)))\n",
    "\n",
    "#adding the roc_score value to the dictionary to assess which is the best\n",
    "# can be calculated with another calculation, but it would be time consuming to do both to show they are identical\n",
    "fpr, tpr, threshold = roc_curve(y_val, y_val_gnb[:,1])\n",
    "roc_test = auc(fpr,tpr)\n",
    "roc_dict[i] = roc_test\n",
    "\n",
    "\n",
    "\n",
    "# getting all the values with the highest accuracy score\n",
    "max_keys = [key for key, value in roc_dict.items() if value == max(roc_dict.values())]\n",
    "\n",
    "# we use the biggest of the neighbors values as the neighbor to use for the classification, as a lower value is not recomended \n",
    "print(roc_dict[max_keys[-1]])\n",
    "\n",
    "#best trained knn algorithm\n",
    "final_knn_trained = knn_list[max_keys[-1]]\n",
    "print(roc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34121f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
