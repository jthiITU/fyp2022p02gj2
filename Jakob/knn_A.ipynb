{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>melanoma</th>\n",
       "      <th>Norm_Compactness</th>\n",
       "      <th>Norm_Asymmetry</th>\n",
       "      <th>Norm_Average Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476510</td>\n",
       "      <td>0.383144</td>\n",
       "      <td>0.576044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397999</td>\n",
       "      <td>0.313298</td>\n",
       "      <td>0.350968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.401858</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.737918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.319373</td>\n",
       "      <td>0.185313</td>\n",
       "      <td>0.648577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369017</td>\n",
       "      <td>0.519001</td>\n",
       "      <td>0.575675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   melanoma  Norm_Compactness  Norm_Asymmetry  Norm_Average Color\n",
       "0       0.0          0.476510        0.383144            0.576044\n",
       "1       0.0          0.397999        0.313298            0.350968\n",
       "2       0.0          0.401858        0.183044            0.737918\n",
       "3       0.0          0.319373        0.185313            0.648577\n",
       "4       0.0          0.369017        0.519001            0.575675"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the features normalised and dropping all the non relevant columns to have a clean start\n",
    "df = pd.read_csv(\"../data/interim/norm_features.csv\")\n",
    "df = df.drop([\"seborrheic_keratosis\", \"Perimeter\", \"Area\", \"image_id\", \"Red\", \"Green\", \"Blue\"], axis=1)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data before feature selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#copying the dataframe. it should be with .copy() but it works like this too\n",
    "df2 = df\n",
    "\n",
    "\n",
    "# Some noisy features\n",
    "noise = np.random.RandomState(42).uniform(0, 0.1, size=(df2.shape[0], 20))\n",
    "\n",
    "# Add the noisy data to the informative features\n",
    "# this is not something that makes sense to me. we add the noise to then ignore it in the next cell\n",
    "X = np.hstack((df2[['Norm_Compactness', 'Norm_Asymmetry', \"Norm_Average Color\"]], noise))\n",
    "y = df2['melanoma']\n",
    "\n",
    "# Split dataset to select feature and evaluate the classifier\n",
    "# the splitting is done by splitting the data into data to be used for training and validation (development of the model --> dev), and data to be used for testing. \n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "        X, y, stratify=y, random_state=0)\n",
    "\n",
    "# the development data is split into training and validation.\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_dev, y_dev, stratify=y_dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select features to train the classifier with \n",
    "X_train2 = X_train[:, [0,2]] # Here just selecting the first three \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.71428571428571"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test to decide which neighbor is best for accuracy:\n",
    "# after deciding which is the best value for the classifier, we proceed to \n",
    "\n",
    "accuracy_dict = {}\n",
    "\n",
    "\n",
    "neigh = int(math.sqrt(len(X_train2)))\n",
    "neigh\n",
    "# the range is to the neigh, as some sources suggest to use the square root of the numebr of datapoints, and it does seem as a fair estimation to decrease error\n",
    "for i in range(1, neigh):\n",
    "    #train the model with different values of the neighbors\n",
    "    knn1 = KNeighborsClassifier(n_neighbors=i) \n",
    "    knn1trained = knn1.fit(X_train2, y_train)\n",
    "    \n",
    "    #Select the same features as before\n",
    "    X_val2 = X_val[:, [0,2]]\n",
    "    y_val_knn1 = knn1trained.predict(X_val2)\n",
    "    \n",
    "    #adding the accuracy value to the dictionary to assess which is the best\n",
    "    # can be calculated with another calculation, but it would be time consimung to do both to show they are identical\n",
    "    accuracy_percentage = accuracy_score(y_val, y_val_knn1)*100\n",
    "    accuracy_dict[i] = accuracy_percentage\n",
    "\n",
    "\n",
    "# getting all the values with the highest accuracy score\n",
    "max_keys = [key for key, value in accuracy_dict.items() if value == max(accuracy_dict.values())]\n",
    "\n",
    "# we use the biggest of the neighbors values as the neighbor to use for the classification, as a lower value is not recomended \n",
    "accuracy_dict[max_keys[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.71428571428571\n"
     ]
    }
   ],
   "source": [
    "# this is a repetition of the previous step, to make sure that the accuracy is high. can be skipped if desired\n",
    "\n",
    "# we choose the neighbor and we fit it with the training data \n",
    "knn1 = KNeighborsClassifier(n_neighbors=max_keys[-1]) \n",
    "knn1trained = knn1.fit(X_train2, y_train)\n",
    "\n",
    "#Select the same features as before from the X validation wth noise\n",
    "X_val2 = X_val[:, [0,2]]\n",
    "\n",
    "# predicting the class labels for the provided data ( the values that were set aside for validating the accuracy of the model)\n",
    "y_val_knn1 = knn1trained.predict(X_val2)\n",
    "\n",
    "\n",
    "# Accuracy \n",
    "print(np.sum(y_val_knn1 == y_val) / np.size(y_val) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " we calculate the accuracy score based on the validation data that we were given. the first parameter is the true values and the second the values that derived.  \n",
    "acc_knn1 = accuracy_score(y_val, y_val_knn1)\n",
    "\n",
    "print(acc_knn1)\n",
    "\n",
    " it shows that we have the same accuracy score both with the function provided and the one we calculate ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# computes the area under the curve based on the true labels and the predicted ones\n",
    "auc1 = roc_auc_score(y_val, y_val_knn1)\n",
    "\n",
    "print(auc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7105263157894737\n",
      "0.45\n"
     ]
    }
   ],
   "source": [
    "# this is the evaluation of the model on the test data that was set aside for this purpose. the accuracy score is lower, but still valid \n",
    "\n",
    "X_test2 = X_test[:, [0,2]]\n",
    "y_test_knn1 = knn1trained.predict(X_test2)\n",
    "\n",
    "acc_test = accuracy_score(y_test, y_test_knn1)\n",
    "print(acc_test)\n",
    "\n",
    "auc_test = roc_auc_score(y_test, y_test_knn1)\n",
    "print(auc_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80eab23de070bf12c95a05150d854f47cf95fcaf8216263797900c0bb6f1aa4b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
