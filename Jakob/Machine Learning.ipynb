{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d632ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, auc, confusion_matrix, precision_score, pairwise\n",
    "import imblearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a90429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the features normalised and dropping all the non relevant columns to have a clean start\n",
    "df = pd.read_csv(\"../data/processed/ISIC_2017_norm_features.csv\")\n",
    "df = df.drop([\"seborrheic_keratosis\", \"Perimeter\", \"Area\", \"image_id\", \"Red\", \"Green\", \"Blue\"], axis=1)\n",
    "\n",
    "df.head()\n",
    "#Note: for sex, 1 is female, 0 is male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data before feature selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#copying the dataframe. it should be with .copy() but it works like this too\n",
    "df2 = df.copy()\n",
    "\n",
    "\n",
    "# Some noisy features\n",
    "noise = np.random.RandomState(42).uniform(0, 0.1, size=(df2.shape[0], 20))\n",
    "\n",
    "# Add the noisy data to the informative features\n",
    "# this is not something that makes sense to me. we add the noise to then ignore it in the next cell\n",
    "X = np.hstack((df2[['Norm_Compactness', 'Norm_Asymmetry', \"Norm_Average Color\"]], noise))\n",
    "y = df2['melanoma'].astype(\"int32\")\n",
    "\n",
    "# Split dataset to select feature and evaluate the classifier\n",
    "# the splitting is done by splitting the data into data to be used for training and validation (development of the model --> dev), and data to be used for testing. \n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "        X, y, stratify=y)\n",
    "\n",
    "# the development data is split into training and validation.\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_dev, y_dev, stratify=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd10fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classifier\n",
    "X_train = X_train[:,0:3] # Take only wanted features\n",
    "roc_dict = {}\n",
    "knn_list = [None]\n",
    "\n",
    "neigh = int(math.sqrt(len(X_train)))\n",
    "neigh\n",
    "# the range is to the neigh, as some sources suggest to use the square root of the number of datapoints, and it does seem as a fair estimation to decrease error\n",
    "for i in range(1, neigh+1):\n",
    "    #train the model with different values of the neighbors\n",
    "    knn1 = KNeighborsClassifier(n_neighbors=i) \n",
    "    knn1trained = knn1.fit(X_train, y_train)\n",
    "    \n",
    "    #Select the same features as before\n",
    "    X_val = X_val[:, 0:3]\n",
    "    y_val_knn1 = knn1trained.predict_proba(X_val)\n",
    "    \n",
    "    #adding the roc_score value to the dictionary to assess which is the best\n",
    "    # can be calculated with another calculation, but it would be time consuming to do both to show they are identical\n",
    "    fpr, tpr, threshold = roc_curve(y_val, y_val_knn1[:,1])\n",
    "    roc_test = auc(fpr,tpr)\n",
    "    roc_dict[i] = roc_test\n",
    "    knn_list.append(knn1trained)\n",
    "\n",
    "\n",
    "# getting all the values with the highest accuracy score\n",
    "max_keys = [key for key, value in roc_dict.items() if value == max(roc_dict.values())]\n",
    "\n",
    "# we use the biggest of the neighbors values as the neighbor to use for the classification, as a lower value is not recomended \n",
    "print(roc_dict[max_keys[-1]])\n",
    "\n",
    "#best trained knn algorithm\n",
    "final_knn_trained = knn_list[max_keys[-1]]\n",
    "y_val_knn1 = knn1trained.predict_proba(X_val)\n",
    "fpr, tpr, threshold = roc_curve(y_val, y_val_knn1[:,1])\n",
    "roc_test = auc(fpr,tpr)\n",
    "\n",
    "\n",
    "\n",
    "print(max_keys[-1])\n",
    "print(roc_auc_score(y_val, final_knn_trained.predict(X_val)), roc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classifier\n",
    "X_train = X_train[:,0:3] # Take only wanted features\n",
    "roc_dict = {}\n",
    "\n",
    "\n",
    "neigh = int(math.sqrt(len(X_train)))\n",
    "neigh\n",
    "# the range is to the neigh, as some sources suggest to use the square root of the number of datapoints, and it does seem as a fair estimation to decrease error\n",
    "for i in range(1, neigh+1):\n",
    "    #train the model with different values of the neighbors\n",
    "    tree1 = DecisionTreeClassifier() \n",
    "    tree1trained = tree1.fit(X_train, y_train)\n",
    "    \n",
    "    #Select the same features as before\n",
    "    X_val = X_val[:, 0:3]\n",
    "    y_val_tree1 = tree1trained.predict(X_val)\n",
    "    \n",
    "    #adding the accuracy value to the dictionary to assess which is the best\n",
    "    # can be calculated with another calculation, but it would be time consuming to do both to show they are identical\n",
    "    roc_test = roc_auc_score(y_val, y_val_tree1)\n",
    "    roc_dict[i] = roc_test\n",
    "\n",
    "\n",
    "# getting all the values with the highest accuracy score\n",
    "max_keys = [key for key, value in roc_dict.items() if value == max(roc_dict.values())]\n",
    "\n",
    "# we use the biggest of the neighbors values as the neighbor to use for the classification, as a lower value is not recomended \n",
    "print(roc_dict[max_keys[-1]])\n",
    "print(roc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = knn1trained.predict_proba(X_val)\n",
    "fpr, tpr, threshold = roc_curve(y_val, y_scores[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN')\n",
    "plt.show()\n",
    "print(y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86bd543",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_knn1 = knn1trained.predict_proba(X_val)\n",
    "fpr, tpr, threshold = roc_curve(y_val, y_val_knn1[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "y_val_knn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tn, fp, fn, tp = (confusion_matrix(y_val,knn1trained.predict(X_val))).ravel()\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1trained.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf883be",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_val,final_knn_trained.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552a0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_val,return_counts= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294005c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88840cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
