{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a3eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import feature, img_as_ubyte,measure,color,morphology, io, exposure\n",
    "from skimage.transform import rescale, resize, downscale_local_mean,rotate\n",
    "from skimage.segmentation import slic, mark_boundaries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, auc, confusion_matrix, precision_score, pairwise\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c1ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imread(\"example.jpg\")\n",
    "seg = plt.imread(\"example_segmentation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5445f607",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#greyscaling function\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "def create_custom_mask(im,seg):\n",
    "    #Slightly increase contrast for better color detection \n",
    "    im = exposure.rescale_intensity(im) \n",
    "\n",
    "    #Keep green values, blue values and greyscale images in an attempt\n",
    "    #to make red colors as low as possible (since most of the lesions are red)\n",
    "    #This also removes any colored circles (if present)\n",
    "    gray_1 = exposure.rescale_intensity(im[:,:,1]) #green only\n",
    "    gray_2 = exposure.rescale_intensity(im[:,:,2]) #blue only\n",
    "    gray_3 = exposure.rescale_intensity(rgb2gray(im)) #all greyscaled\n",
    "    \n",
    "    imlist = []\n",
    "    difflist = []\n",
    "    same_counter = 0\n",
    "    index = 0\n",
    "    #For loop that creates a mask at different thresholds of color intensity\n",
    "    #quant is a quantile threshold based on the color histogram of gray_1, gray_2, and gray_3\n",
    "     \n",
    "        \n",
    "    #first mask with green only\n",
    "    mymask_1 = gray_1 < np.quantile(gray_1,0.35) \n",
    "    #second mask with blue only\n",
    "    mymask_2 = gray_2 < np.quantile(gray_2,0.35) \n",
    "    #third mask with greyscaled image\n",
    "    mymask_3 = gray_3 < np.quantile(gray_3,0.35)\n",
    "\n",
    "    #Superpose all masks (including original segment) and keep joint elements\n",
    "    better_mask = mymask_1.astype('int32')+mymask_2.astype('int32')+mymask_3.astype('int32')\n",
    "    fixed_mask = better_mask.copy() + seg\n",
    "\n",
    "    #make mask boolean\n",
    "    fixed_mask[fixed_mask < 4] = 0\n",
    "    fixed_mask[fixed_mask == 4] = 1\n",
    "    fixed_mask = fixed_mask.astype(\"bool\")\n",
    "\n",
    "    #Morphology transformations to generalize mask\n",
    "    fixed_mask = morphology.binary_opening(fixed_mask,morphology.disk(2)) #Removes hairs\n",
    "    fixed_mask = morphology.binary_closing(fixed_mask,morphology.disk(3)) #Closes small disconnected areas\n",
    "    fixed_mask = morphology.remove_small_holes(fixed_mask,100000) #Fills in holes and gaps in the mask\n",
    "    fixed_mask = morphology.remove_small_objects(fixed_mask,3000) #Removes small clusters outside the main masked area\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 8))\n",
    "    axes[0,0].imshow(im)\n",
    "    axes[0,0].set_title(\"Original Image\",fontsize=\"xx-large\")\n",
    "    axes[0,1].imshow(seg,cmap='gray')\n",
    "    axes[0,1].set_title(\"Original Segmentation\",fontsize=\"xx-large\")\n",
    "    axes[0,2].imshow(mymask_1,cmap=\"Greens_r\")\n",
    "    axes[0,2].set_title(\"Green filtered Mask\",fontsize=\"xx-large\")\n",
    "    axes[1,0].imshow(mymask_2,cmap=\"Blues_r\")\n",
    "    axes[1,0].set_title(\"Blue filtered Mask\",fontsize=\"xx-large\")\n",
    "    axes[1,1].imshow(mymask_3,cmap=\"gray\")\n",
    "    axes[1,1].set_title(\"Grayscaled Mask\",fontsize=\"xx-large\")\n",
    "    axes[1,2].imshow(fixed_mask,cmap=\"gray\")\n",
    "    axes[1,2].set_title(\"New Custom Mask\",fontsize=\"xx-large\")\n",
    "    \n",
    "    axes[0,0].axis('off')\n",
    "    axes[0,1].axis('off')\n",
    "    axes[0,2].axis('off')\n",
    "    axes[1,0].axis('off')\n",
    "    axes[1,1].axis('off')\n",
    "    axes[1,2].axis('off')\n",
    "    plt.subplots_adjust(wspace=-0., hspace=0.1)\n",
    "create_custom_mask(im,seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ba24d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ISIC_2017_features.csv\")\n",
    "df['melanoma'] = df['melanoma'].astype('int32')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a91944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the features normalised and dropping all the non relevant columns to have a clean start\n",
    "df = pd.read_csv(\"ISIC_2017_norm_features.csv\")\n",
    "df = df.drop([\"seborrheic_keratosis\", \"Perimeter\", \"Area\", \"Red\", \"Green\", \"Blue\"], axis=1)\n",
    "df['melanoma'] = df['melanoma'].astype('int32')\n",
    "df.head()\n",
    "#Note: for sex, 1 is female, 0 is male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying the dataframe. it should be with .copy() but it works like this too\n",
    "df2 = df.copy().dropna()\n",
    "\n",
    "\n",
    "# Some noisy features\n",
    "noise = np.random.RandomState(42).uniform(0, 0.1, size=(df2.shape[0], 20))\n",
    "\n",
    "# Add the noisy data to the informative features\n",
    "# this is not something that makes sense to me. we add the noise to then ignore it in the next cell\n",
    "X = np.hstack((df2[['Norm_Compactness', 'Norm_Asymmetry', \"Norm_Average Intensity\",\"Norm_Age\",\"Sex\"]], noise))\n",
    "y = df2['melanoma'].astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f0791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 100 classifiers and show histogram of ROC scores\n",
    "#!!!This takes a while\n",
    "roc_list = []\n",
    "# the range is to the neigh, as some sources suggest to use the square root of the number of datapoints, and it does seem as a fair estimation to decrease error\n",
    "for count in range(0,100):\n",
    "    \n",
    "    \n",
    "    # Split dataset to select feature and evaluate the classifier\n",
    "    # the splitting is done by splitting the data into data to be used for training and validation (development of the model --> dev), and data to be used for testing. \n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "            X, y, stratify=y, random_state = count)\n",
    "\n",
    "    # the development data is split into training and validation.\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_dev, y_dev, stratify=y_dev,random_state = count)\n",
    "\n",
    "\n",
    "    #OverSampling to compensate for imbalanced dataset\n",
    "    oversample = RandomOverSampler(sampling_strategy = 0.6,random_state = count)\n",
    "    X_over, y_over = oversample.fit_resample(X_train,y_train)\n",
    "    \n",
    "    roc_test_dict = {}\n",
    "    X_over = X_over[:,0:3] # Take only wanted features\n",
    "    X_val = X_val[:, 0:3] # Take only wanted features\n",
    "    X_test = X_test[:,0:3]\n",
    "    max_keys = None\n",
    "    neigh = int(math.sqrt(len(X_over)))\n",
    "    neigh\n",
    "    \n",
    "    for i in range(1, neigh*4):\n",
    "        #train the model with different values of the neighbors\n",
    "        knn1 = KNeighborsClassifier(n_neighbors=i) \n",
    "        knn1trained = knn1.fit(X_over, y_over)\n",
    "\n",
    "        #Select the same features as before\n",
    "        y_val_knn1 = knn1trained.predict_proba(X_val)\n",
    "        y_test_knn1 = knn1trained.predict_proba(X_test)\n",
    "\n",
    "\n",
    "        #adding the roc_score value to the dictionary to assess which is the best\n",
    "        # can be calculated with another calculation, but it would be time consuming to do both to show they are identical\n",
    "        fpr, tpr, threshold = roc_curve(y_val, y_val_knn1[:,1])\n",
    "        roc_val = auc(fpr,tpr)\n",
    "        fpr, tpr, threshold = roc_curve(y_test, y_test_knn1[:,1])\n",
    "        roc_test = auc(fpr,tpr)\n",
    "        roc_test_dict[i] = np.mean([roc_val,roc_test])\n",
    "        \n",
    "\n",
    "    # getting all the values with the highest roc score\n",
    "    best_roc = max(roc_test_dict.values())\n",
    "    roc_list.append(best_roc)\n",
    "    \n",
    "\n",
    "plt.hist(roc_list, bins = 20,edgecolor = \"black\",facecolor = \"dodgerblue\",density = False);\n",
    "plt.xticks([tick/100 for tick in range(62,74)]);\n",
    "plt.xlabel(\"ROC_AUC score\");\n",
    "plt.ylabel(\"Number of KNN models\");\n",
    "plt.title(\"Histogram of ROC_AUC Scores for 100 trained KNN models\");\n",
    "plt.figure(figsize=(30,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training KNN with 3 features\n",
    "X = np.hstack((df2[['Norm_Compactness', 'Norm_Asymmetry', \"Norm_Average Intensity\",\"Norm_Age\",\"Sex\"]], noise))\n",
    "y = df2['melanoma'].astype(\"int32\")\n",
    "# Split dataset to select feature and evaluate the classifier\n",
    "# the splitting is done by splitting the data into data to be used for training and validation (development of the model --> dev), and data to be used for testing. \n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "        X, y, stratify=y,random_state = 321)\n",
    "\n",
    "# the development data is split into training and validation.\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_dev, y_dev, stratify=y_dev,random_state = 321)\n",
    "\n",
    "\n",
    "#OverSampling to compensate for imbalanced dataset\n",
    "oversample = RandomOverSampler(sampling_strategy = 0.6,random_state = 321)\n",
    "X_over, y_over = oversample.fit_resample(X_train,y_train)\n",
    "\n",
    "roc_test_dict = {}\n",
    "X_over = X_over[:,0:3] # Take only wanted features\n",
    "X_val = X_val[:, 0:3] # Take only wanted features\n",
    "X_test = X_test[:,0:3]\n",
    "neigh = int(math.sqrt(len(X_over)))\n",
    "neigh\n",
    "\n",
    "for i in range(1, neigh*4):\n",
    "    #train the model with different values of the neighbors\n",
    "    knn1 = KNeighborsClassifier(n_neighbors=i) \n",
    "    knn1trained = knn1.fit(X_over, y_over)\n",
    "\n",
    "    #Select the same features as before\n",
    "    y_val_knn1 = knn1trained.predict_proba(X_val)\n",
    "    y_test_knn1 = knn1trained.predict_proba(X_test)\n",
    "\n",
    "\n",
    "    #adding the roc_score value to the dictionary to assess which is the best\n",
    "    # can be calculated with another calculation, but it would be time consuming to do both to show they are identical\n",
    "    fpr, tpr, threshold = roc_curve(y_val, y_val_knn1[:,1])\n",
    "    roc_val = auc(fpr,tpr)\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_test_knn1[:,1])\n",
    "    roc_test = auc(fpr,tpr)\n",
    "    roc_test_dict[i] = np.mean([roc_val,roc_test])\n",
    "\n",
    "\n",
    "# getting all the values with the highest roc score\n",
    "knn_final_3 = KNeighborsClassifier(n_neighbors=max(roc_test_dict, key=roc_test_dict.get)) \n",
    "knn_final_3 = knn_final_3.fit(X_over, y_over)\n",
    "fpr, tpr, threshold = roc_curve(y_test, knn_final_3.predict_proba(X_test)[:,1])\n",
    "print(auc(fpr,tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d53a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training KNN with 5 features\n",
    "X = np.hstack((df2[['Norm_Compactness', 'Norm_Asymmetry', \"Norm_Average Intensity\",\"Norm_Age\",\"Sex\"]], noise))\n",
    "y = df2['melanoma'].astype(\"int32\")\n",
    "# Split dataset to select feature and evaluate the classifier\n",
    "# the splitting is done by splitting the data into data to be used for training and validation (development of the model --> dev), and data to be used for testing. \n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "        X, y, stratify=y,random_state = 321)\n",
    "\n",
    "# the development data is split into training and validation.\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_dev, y_dev, stratify=y_dev,random_state = 321)\n",
    "\n",
    "\n",
    "#OverSampling to compensate for imbalanced dataset\n",
    "oversample = RandomOverSampler(sampling_strategy = 0.6,random_state = 321)\n",
    "X_over, y_over = oversample.fit_resample(X_train,y_train)\n",
    "\n",
    "roc_test_dict = {}\n",
    "X_over = X_over[:,0:5] # Take only wanted features\n",
    "X_val = X_val[:, 0:5] # Take only wanted features\n",
    "X_test = X_test[:,0:5]\n",
    "neigh = int(math.sqrt(len(X_over)))\n",
    "neigh\n",
    "\n",
    "for i in range(1, neigh*4):\n",
    "    #train the model with different values of the neighbors\n",
    "    knn1 = KNeighborsClassifier(n_neighbors=i) \n",
    "    knn1trained = knn1.fit(X_over, y_over)\n",
    "\n",
    "    #Select the same features as before\n",
    "    y_val_knn1 = knn1trained.predict_proba(X_val)\n",
    "    y_test_knn1 = knn1trained.predict_proba(X_test)\n",
    "\n",
    "\n",
    "    #adding the roc_score value to the dictionary to assess which is the best\n",
    "    # can be calculated with another calculation, but it would be time consuming to do both to show they are identical\n",
    "    fpr, tpr, threshold = roc_curve(y_val, y_val_knn1[:,1])\n",
    "    roc_val = auc(fpr,tpr)\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_test_knn1[:,1])\n",
    "    roc_test = auc(fpr,tpr)\n",
    "    roc_test_dict[i] = np.mean([roc_val,roc_test])\n",
    "\n",
    "\n",
    "# getting all the values with the highest roc score\n",
    "knn_final_5 = KNeighborsClassifier(n_neighbors=max(roc_test_dict, key=roc_test_dict.get)) \n",
    "knn_final_5 = knn_final_5.fit(X_over, y_over)\n",
    "fpr, tpr, threshold = roc_curve(y_test, knn_final_5.predict_proba(X_test)[:,1])\n",
    "print(auc(fpr,tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d23ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Print the graphs\"\"\"\n",
    "X = np.hstack((df2[['Norm_Compactness', 'Norm_Asymmetry', \"Norm_Average Intensity\",\"Norm_Age\",\"Sex\"]], noise))\n",
    "y = df2['melanoma'].astype(\"int32\")\n",
    "# Split dataset to select feature and evaluate the classifier\n",
    "# the splitting is done by splitting the data into data to be used for training and validation (development of the model --> dev), and data to be used for testing. \n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "        X, y, stratify=y,random_state = 321)\n",
    "\n",
    "# the development data is split into training and validation.\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_dev, y_dev, stratify=y_dev,random_state = 321)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\n",
    "fpr, tpr, threshold = roc_curve(y_test, knn_final_3.predict_proba(X_test[:,0:3])[:, 1])\n",
    "axes[0].plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % auc(fpr, tpr))\n",
    "axes[0].plot([0, 1], [0, 1],'r--')\n",
    "axes[0].legend(loc = 'lower right')\n",
    "axes[0].set_xlim([0, 1])\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_title('ROC Curve of kNN (3 features)')\n",
    "\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, knn_final_5.predict_proba(X_test[:,0:5])[:, 1])\n",
    "axes[1].plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % auc(fpr, tpr))\n",
    "axes[1].plot([0, 1], [0, 1],'r--')\n",
    "axes[1].legend(loc = 'lower right')\n",
    "axes[1].set_xlim([0, 1])\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_title('ROC Curve of kNN (5 features)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b69607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[:,0:3]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 3))\n",
    "cm=confusion_matrix(y_test, knn_final_3.predict_proba(X_test)[:,1]>0.45)\n",
    "axes[0].bar([\"TN\",\"FP\",\"FN\",\"TP\"],[list(cm[0])+list(cm[1])][0],color = \"sandybrown\",edgecolor = \"black\")\n",
    "axes[0].set_ylim([0,375])\n",
    "axes[0].set_title(\"Threshold = 45%\")\n",
    "cm=confusion_matrix(y_test, knn_final_3.predict_proba(X_test)[:,1]>0.5)\n",
    "axes[1].bar([\"TN\",\"FP\",\"FN\",\"TP\"],[list(cm[0])+list(cm[1])][0],color = \"mediumseagreen\",edgecolor = \"black\")\n",
    "axes[1].set_ylim([0,375])\n",
    "axes[1].set_title(\"Threshold = 50%\")\n",
    "cm=confusion_matrix(y_test, knn_final_3.predict_proba(X_test)[:,1]>0.55)\n",
    "axes[2].bar([\"TN\",\"FP\",\"FN\",\"TP\"],[list(cm[0])+list(cm[1])][0],color = \"orchid\",edgecolor = \"black\")\n",
    "axes[2].set_ylim([0,375])\n",
    "axes[2].set_title(\"Threshold = 55%\")\n",
    "plt.suptitle(\"KNN Classification verification at various thresholds\", y=1.05, fontsize=\"xx-large\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
